{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EEG Signal Classification Notebook\n",
    "\n",
    "## Walkthrough\n",
    "\n",
    "The main objective of this task is to obtain a neural representation from the output of both a typical Convulutional Neural Network which feeds on images and from a Convolutional Neural Network which processes and classifies EEG signals, and compare the obtained representations in order to try and find a correlation between the two.\n",
    "\n",
    "### Setup\n",
    "\n",
    "Let\"s start by importing `torch` (PyTorch)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the original file, we defined the different arguments using the `argparse` library. In this notebook, we devote a whole cell to define all the arguments needed by our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS (Metal) available\n"
     ]
    }
   ],
   "source": [
    "EEG_DATASET_PATH = \"data/eeg_5_95_std.pth\"\n",
    "\n",
    "SPLITS_PATH = \"data/block_splits_by_image_all.pth\"\n",
    "\n",
    "# Leave this always to zero\n",
    "SPLIT_NUM = 0\n",
    "\n",
    "# Subject selecting\n",
    "# Choose a subject from 1 to 6, default is 0 (all subjects)\n",
    "SUBJECT = 0\n",
    "\n",
    "# Time options: select from 20 to 460 samples from EEG data\n",
    "TIME_LOW = 20\n",
    "TIME_HIGH = 460\n",
    "\n",
    "# Model type/options\n",
    "# Specify which generator should be used. Available: lstm | EEGChannelNet\n",
    "# It is possible to test out multiple deep classifiers:\n",
    "#   - lstm is the model described in the paper \n",
    "#     \"Deep Learning Human Mind for Automated Visual Classification‚Äù, CVPR 2017\n",
    "#   - model10 is the model described in the paper \n",
    "#     \"Decoding brain representations by multimodal learning of neural activity and visual features\", TPAMI 2020\n",
    "MODEL_TYPE = \"lstm\"\n",
    "\n",
    "MODEL_PARAMS = \"\"\n",
    "PRETRAINED_NET = \"\"\n",
    "\n",
    "# Training options\n",
    "BATCH_SIZE = 16\n",
    "OPTIMIZER = \"Adam\"\n",
    "LEARNING_RATE = 0.0001\n",
    "LEARNING_RATE_DECAY_BY = 0.5\n",
    "LEARNING_RATE_DECAY_EVERY = 10\n",
    "DATA_WORKERS = 4\n",
    "EPOCHS = 200\n",
    "\n",
    "# Save every SAVE_CHECK epochs\n",
    "SAVE_CHECK = 2\n",
    "\n",
    "# Backend options\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device(\"cuda\")\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    print(\"CUDA available\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    DEVICE = torch.device(\"mps\")\n",
    "    print(\"MPS (Metal) available\")\n",
    "else:\n",
    "    DEVICE = torch.device(\"cpu\")\n",
    "    print(\"CPU available\")\n",
    "\n",
    "torch.utils.backcompat.broadcast_warning.enabled = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define our `EEGDataset` and `Splitter` classes as defined in the file [`eeg_signal_classification.py`](./eeg_signal_classification.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGDataset:\n",
    "    def __init__(self, eeg_signals_path, subject=0, time_low=20, time_high=460, model_type=\"lstm\"):\n",
    "        self.subject = subject\n",
    "        self.time_low = time_low\n",
    "        self.time_high = time_high\n",
    "        self.model_type = model_type\n",
    "\n",
    "        # Load EEG signals\n",
    "        loaded = torch.load(eeg_signals_path)\n",
    "        if subject != 0:\n",
    "            self.data = [loaded[\"dataset\"][i] for i in range(\n",
    "                len(loaded[\"dataset\"])) if loaded[\"dataset\"][i][\"subject\"] == subject]\n",
    "        else:\n",
    "            self.data = loaded[\"dataset\"]\n",
    "        self.labels = loaded[\"labels\"]\n",
    "        self.images = loaded[\"images\"]\n",
    "\n",
    "        # Compute size\n",
    "        self.size = len(self.data)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.size\n",
    "\n",
    "    # Get item\n",
    "    def __getitem__(self, i):\n",
    "        # Process EEG\n",
    "        eeg = self.data[i][\"eeg\"].float().t()\n",
    "        eeg = eeg[self.time_low:self.time_high, :]\n",
    "\n",
    "        if self.model_type == \"model10\":\n",
    "            eeg = eeg.t()\n",
    "            eeg = eeg.view(1, 128, self.time_high - self.time_low)\n",
    "        # Get label\n",
    "        label = self.data[i][\"label\"]\n",
    "        \n",
    "        return eeg, label\n",
    "\n",
    "class Splitter:\n",
    "    def __init__(self, dataset, split_path, split_num=0, split_name=\"train\"):\n",
    "        # Set EEG dataset\n",
    "        self.dataset = dataset\n",
    "        # Load split\n",
    "        loaded = torch.load(split_path)\n",
    "        self.split_idx = loaded[\"splits\"][split_num][split_name]\n",
    "        # Filter data\n",
    "        self.split_idx = [i for i in self.split_idx if 450 <=\n",
    "                          self.dataset.data[i][\"eeg\"].size(1) <= 600]\n",
    "        # Compute size\n",
    "        self.size = len(self.split_idx)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.size\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        # Get sample from dataset\n",
    "        eeg, label = self.dataset[self.split_idx[i]]\n",
    "        \n",
    "        return eeg, label\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Dataset and Model initialization\n",
    "\n",
    "Let's now create the dataset and load the model using the data from the original paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dataset = EEGDataset(EEG_DATASET_PATH)\n",
    "loaders = {\n",
    "    split: DataLoader(\n",
    "        Splitter(dataset, split_path=SPLITS_PATH, split_num=SPLIT_NUM, split_name=split),\n",
    "        batch_size=BATCH_SIZE, drop_last=True, shuffle=True\n",
    "    ) for split in [\"train\", \"val\", \"test\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's load the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "\n",
    "# Load model\n",
    "model_options = {\n",
    "    key: int(value) if value.isdigit() else (\n",
    "        float(value) if value[0].isdigit() else value\n",
    "    ) for (key, value) in [x.split(\"=\") for x in MODEL_PARAMS]\n",
    "}\n",
    "\n",
    "# Create discriminator model/optimizer\n",
    "module = importlib.import_module(\"models.\" + MODEL_TYPE)\n",
    "model = module.Model(**model_options)\n",
    "optimizer = getattr(torch.optim, OPTIMIZER)(model.parameters(), lr=LEARNING_RATE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's move the models to the appropriate backend device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model has been moved to device 'mps'\n"
     ]
    }
   ],
   "source": [
    "model.to(DEVICE)\n",
    "print(f\"Model has been moved to device '{DEVICE}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load a pretrained model if we specified a path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Model(\n",
      "  (lstm): LSTM(128, 128, batch_first=True)\n",
      "  (output): Linear(in_features=128, out_features=128, bias=True)\n",
      "  (classifier): Linear(in_features=128, out_features=40, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "if PRETRAINED_NET != \"\":\n",
    "    print(f\"Loading a pretrained model from '{PRETRAINED_NET}'\")\n",
    "    model = torch.load(PRETRAINED_NET)\n",
    "    \n",
    "print(f\"Model: {model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training, Validation and Test options setup\n",
    "\n",
    "Let's now set up the training/validation/test options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize training,validation, test losses and accuracy list\n",
    "losses_per_epoch = {\"train\": [], \"val\": [], \"test\": []}\n",
    "accuracies_per_epoch = {\"train\": [], \"val\": [], \"test\": []}\n",
    "\n",
    "best_accuracy = 0\n",
    "best_accuracy_val = 0\n",
    "best_epoch = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loop\n",
    "\n",
    "Now we can finally run the training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "# Start training\n",
    "predicted_labels = [] \n",
    "correct_labels = []\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    # Initialize loss/accuracy variables\n",
    "    losses = {\"train\": 0, \"val\": 0, \"test\": 0}\n",
    "    accuracies = {\"train\": 0, \"val\": 0, \"test\": 0}\n",
    "    counts = {\"train\": 0, \"val\": 0, \"test\": 0}\n",
    "    \n",
    "    # Adjust learning rate for SGD\n",
    "    if OPTIMIZER == \"SGD\":\n",
    "        lr = LEARNING_RATE * (LEARNING_RATE_DECAY_BY ** (epoch // LEARNING_RATE_DECAY_EVERY))\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group[\"lr\"] = lr\n",
    "    \n",
    "    # Process each split\n",
    "    for split in (\"train\", \"val\", \"test\"):\n",
    "        # Set network mode\n",
    "        if split == \"train\":\n",
    "            model.train()\n",
    "            torch.set_grad_enabled(True)\n",
    "        else:\n",
    "            model.eval()\n",
    "            torch.set_grad_enabled(False)\n",
    "        \n",
    "        # Process all split batches\n",
    "        for i, (input, target) in enumerate(loaders[split]):\n",
    "            # Move tensors to device\n",
    "            input.to(DEVICE) \n",
    "            target.to(DEVICE)\n",
    "            \n",
    "            # Forward\n",
    "            output = model(input)\n",
    "\n",
    "            # Compute loss\n",
    "            loss = F.cross_entropy(output, target)\n",
    "            losses[split] += loss.item()\n",
    "            \n",
    "            # Compute accuracy\n",
    "            _, pred = output.data.max(1)\n",
    "            correct = pred.eq(target.data).sum().item()\n",
    "            accuracy = correct/input.data.size(0)   \n",
    "            accuracies[split] += accuracy\n",
    "            counts[split] += 1\n",
    "            \n",
    "            # Backward and optimize\n",
    "            if split == \"train\":\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "    \n",
    "    # Print info at the end of the epoch\n",
    "    if accuracies[\"val\"] / counts[\"val\"] >= best_accuracy_val:\n",
    "        best_accuracy_val = accuracies[\"val\"] / counts[\"val\"]\n",
    "        best_accuracy = accuracies[\"test\"] / counts[\"test\"]\n",
    "        best_epoch = epoch\n",
    "\n",
    "    train_loss = losses[\"train\"] / counts[\"train\"]\n",
    "    train_accuracy = accuracies[\"train\"] / counts[\"train\"]\n",
    "    validation_loss = losses[\"val\"] / counts[\"val\"]\n",
    "    validation_accuracy = accuracies[\"val\"] / counts[\"val\"]\n",
    "    test_loss = losses[\"test\"] / counts[\"test\"]\n",
    "    test_accuracy = accuracies[\"test\"] / counts[\"test\"]\n",
    "\n",
    "    print(\"\\nINFO\")\n",
    "    print(f\"- Model: {MODEL_TYPE}\")\n",
    "    print(f\"- Subject: {SUBJECT}\")\n",
    "    print(f\"- Time interval: [{TIME_LOW}-{TIME_HIGH}] [{TIME_LOW}-{TIME_HIGH} Hz]\")\n",
    "    print(f\"- Epoch: {epoch}\")\n",
    "    print(\"\\nSTATS\")\n",
    "    print(f\"- Training: Loss {train_loss:.4f}, Accuracy {train_accuracy:.4f}\")\n",
    "    print(f\"- Validation: Loss {validation_loss:.4f}, Accuracy {validation_accuracy:.4f}\")\n",
    "    print(f\"- Test: Loss {test_loss:.4f}, Accuracy {test_accuracy:.4f}\")\n",
    "    print(f\"Best Test Accuracy at maximum Validation Accuracy (validation_accuracy = {best_accuracy_val}) is {best_accuracy} at epoch {best_epoch}\")\n",
    "\n",
    "    losses_per_epoch[\"train\"].append(train_loss)\n",
    "    losses_per_epoch[\"val\"].append(validation_loss)\n",
    "    losses_per_epoch[\"test\"].append(test_loss)\n",
    "    accuracies_per_epoch[\"train\"].append(train_accuracy)\n",
    "    accuracies_per_epoch[\"val\"].append(validation_accuracy)\n",
    "    accuracies_per_epoch[\"test\"].append(test_accuracy)\n",
    "\n",
    "    if epoch % SAVE_CHECK == 0:\n",
    "        torch.save(model, f\"{MODEL_TYPE}__subject{SUBJECT}_epoch_{epoch}.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c6e4e9f98eb68ad3b7c296f83d20e6de614cb42e90992a65aa266555a3137d0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
