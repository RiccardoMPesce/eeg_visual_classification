{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EEG Signal Classification Notebook\n",
    "\n",
    "## Walkthrough\n",
    "\n",
    "The main objective of this task is to obtain a neural representation from the output of both a typical Convulutional Neural Network which feeds on images and from a Convolutional Neural Network which processes and classifies EEG signals, and compare the obtained representations in order to try and find a correlation between the two.\n",
    "\n",
    "### Setup\n",
    "\n",
    "Let\"s start by importing `torch` (PyTorch)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Platform used: macOS-12.5-arm64-arm-64bit\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import platform\n",
    "\n",
    "print(f\"Platform used: {platform.platform()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the original file, we defined the different arguments using the `argparse` library. In this notebook, we devote a whole cell to define all the arguments needed by our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS (Metal) available\n"
     ]
    }
   ],
   "source": [
    "from genericpath import isdir\n",
    "from pathlib import Path\n",
    "\n",
    "EEG_DATASET_PATH = Path(\"data/eeg_5_95_std.pth\")\n",
    "\n",
    "CHECKPOINT_PATH = Path(\"model_checkpoints\")\n",
    "\n",
    "CHECKPOINT_PATH.mkdir(exist_ok=True)\n",
    "\n",
    "SPLITS_PATH = \"data/block_splits_by_image_all.pth\"\n",
    "\n",
    "# Leave this always to zero\n",
    "SPLIT_NUM = 0\n",
    "\n",
    "# Subject selecting\n",
    "# Choose a subject from 1 to 6, default is 0 (all subjects)\n",
    "SUBJECT = 0\n",
    "\n",
    "# Time options: select from 20 to 460 samples from EEG data\n",
    "TIME_LOW = 20\n",
    "TIME_HIGH = 460\n",
    "\n",
    "# Model type/options\n",
    "# Specify which generator should be used. Available: lstm | EEGChannelNet\n",
    "# It is possible to test out multiple deep classifiers:\n",
    "#   - lstm is the model described in the paper \n",
    "#     \"Deep Learning Human Mind for Automated Visual Classification‚Äù, CVPR 2017\n",
    "#   - model10 is the model described in the paper \n",
    "#     \"Decoding brain representations by multimodal learning of neural activity and visual features\", TPAMI 2020\n",
    "MODEL_TYPE = \"lstm\"\n",
    "\n",
    "MODEL_PARAMS = \"\"\n",
    "PRETRAINED_NET = \"\"\n",
    "\n",
    "# Training options\n",
    "BATCH_SIZE = 16\n",
    "OPTIMIZER = \"Adam\"\n",
    "LEARNING_RATE = 0.0001\n",
    "LEARNING_RATE_DECAY_BY = 0.5\n",
    "LEARNING_RATE_DECAY_EVERY = 10\n",
    "DATA_WORKERS = 4\n",
    "EPOCHS = 200\n",
    "\n",
    "# Save every SAVE_CHECK epochs\n",
    "SAVE_CHECK = 2\n",
    "\n",
    "# Backend options\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device(\"cuda\")\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    print(\"CUDA available\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    DEVICE = torch.device(\"mps\")\n",
    "    # BATCH_SIZE = 440\n",
    "    print(\"MPS (Metal) available\")\n",
    "else:\n",
    "    DEVICE = torch.device(\"cpu\")\n",
    "    print(\"CPU available\")\n",
    "\n",
    "torch.utils.backcompat.broadcast_warning.enabled = True\n",
    "\n",
    "# Force CPU\n",
    "# print(\"Forcing CPU\")\n",
    "# DEVICE = torch.device(\"cpu\")\n",
    "\n",
    "# Debug Mode\n",
    "DEBUG = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define our `EEGDataset` and `Splitter` classes as defined in the file [`eeg_signal_classification.py`](./eeg_signal_classification.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGDataset:\n",
    "    def __init__(self, eeg_signals_path, subject=0, time_low=20, time_high=460, model_type=\"lstm\"):\n",
    "        self.subject = subject\n",
    "        self.time_low = time_low\n",
    "        self.time_high = time_high\n",
    "        self.model_type = model_type\n",
    "\n",
    "        # Load EEG signals\n",
    "        loaded = torch.load(eeg_signals_path)\n",
    "        if subject != 0:\n",
    "            self.data = [loaded[\"dataset\"][i] for i in range(\n",
    "                len(loaded[\"dataset\"])) if loaded[\"dataset\"][i][\"subject\"] == subject]\n",
    "        else:\n",
    "            self.data = loaded[\"dataset\"]\n",
    "        self.labels = loaded[\"labels\"]\n",
    "        self.images = loaded[\"images\"]\n",
    "\n",
    "        # Compute size\n",
    "        self.size = len(self.data)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.size\n",
    "\n",
    "    # Get item\n",
    "    def __getitem__(self, i):\n",
    "        # Process EEG\n",
    "        eeg = self.data[i][\"eeg\"].float().t()\n",
    "        eeg = eeg[self.time_low:self.time_high, :]\n",
    "\n",
    "        if self.model_type == \"model10\":\n",
    "            eeg = eeg.t()\n",
    "            eeg = eeg.view(1, 128, self.time_high - self.time_low)\n",
    "        # Get label\n",
    "        label = self.data[i][\"label\"]\n",
    "        \n",
    "        return eeg, label\n",
    "\n",
    "class Splitter:\n",
    "    def __init__(self, dataset, split_path, split_num=0, split_name=\"train\"):\n",
    "        # Set EEG dataset\n",
    "        self.dataset = dataset\n",
    "        # Load split\n",
    "        loaded = torch.load(split_path)\n",
    "        self.split_idx = loaded[\"splits\"][split_num][split_name]\n",
    "        # Filter data\n",
    "        self.split_idx = [i for i in self.split_idx if 450 <=\n",
    "                          self.dataset.data[i][\"eeg\"].size(1) <= 600]\n",
    "        # Compute size\n",
    "        self.size = len(self.split_idx)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.size\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        # Get sample from dataset\n",
    "        eeg, label = self.dataset[self.split_idx[i]]\n",
    "        \n",
    "        return eeg, label\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Dataset and Model initialization\n",
    "\n",
    "Let's now create the dataset and load the model using the data from the original paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dataset = EEGDataset(EEG_DATASET_PATH)\n",
    "loaders = {\n",
    "    split: DataLoader(\n",
    "        Splitter(dataset, split_path=SPLITS_PATH, split_num=SPLIT_NUM, split_name=split),\n",
    "        batch_size=BATCH_SIZE, drop_last=True, shuffle=True\n",
    "    ) for split in [\"train\", \"val\", \"test\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's load the model, move to the appropriate device and let's create the optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model has been moved to device 'mps'\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "\n",
    "# Load model\n",
    "model_options = {\n",
    "    key: int(value) if value.isdigit() else (\n",
    "        float(value) if value[0].isdigit() else value\n",
    "    ) for (key, value) in [x.split(\"=\") for x in MODEL_PARAMS]\n",
    "}\n",
    "\n",
    "# Create discriminator model/optimizer\n",
    "module = importlib.import_module(\"models.\" + MODEL_TYPE)\n",
    "model = module.Model(**model_options)\n",
    "# Moving model to the appropriate device\n",
    "model.to(DEVICE)\n",
    "print(f\"Model has been moved to device '{DEVICE}'\")\n",
    "# Creating the optimizer\n",
    "optimizer = getattr(torch.optim, OPTIMIZER)(model.parameters(), lr=LEARNING_RATE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load a pretrained model if we specified a path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Model(\n",
      "  (lstm): LSTM(128, 128, batch_first=True)\n",
      "  (output): Linear(in_features=128, out_features=128, bias=True)\n",
      "  (classifier): Linear(in_features=128, out_features=40, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "if PRETRAINED_NET != \"\":\n",
    "    print(f\"Loading a pretrained model from '{PRETRAINED_NET}'\")\n",
    "    model = torch.load(PRETRAINED_NET)\n",
    "    model.to(DEVICE)\n",
    "    \n",
    "print(f\"Model: {model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training, Validation and Test options setup\n",
    "\n",
    "Let's now set up the training/validation/test options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize training,validation, test losses and accuracy list\n",
    "losses_per_epoch = {\"train\": [], \"val\": [], \"test\": []}\n",
    "accuracies_per_epoch = {\"train\": [], \"val\": [], \"test\": []}\n",
    "\n",
    "best_accuracy = 0\n",
    "best_accuracy_val = 0\n",
    "best_epoch = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loop\n",
    "\n",
    "Now we can finally run the training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'torch.device' object has no attribute 'startswith'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/riccardopesce/Work/University/AI/eeg_visual_classification/main.ipynb Cella 16\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/riccardopesce/Work/University/AI/eeg_visual_classification/main.ipynb#X21sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39minput\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/riccardopesce/Work/University/AI/eeg_visual_classification/main.ipynb#X21sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m \u001b[39m# Forward\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/riccardopesce/Work/University/AI/eeg_visual_classification/main.ipynb#X21sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m output \u001b[39m=\u001b[39m model(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/riccardopesce/Work/University/AI/eeg_visual_classification/main.ipynb#X21sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m \u001b[39m# Compute loss\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/riccardopesce/Work/University/AI/eeg_visual_classification/main.ipynb#X21sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m loss \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mcross_entropy(output, target)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/nightly-pytorch/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Work/University/AI/eeg_visual_classification/models/lstm.py:53\u001b[0m, in \u001b[0;36mModel.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     50\u001b[0m lstm_init \u001b[39m=\u001b[39m (Variable(lstm_init[\u001b[39m0\u001b[39m]), Variable(lstm_init[\u001b[39m1\u001b[39m]))\n\u001b[1;32m     52\u001b[0m \u001b[39m# Forward LSTM and get final state\u001b[39;00m\n\u001b[0;32m---> 53\u001b[0m \u001b[39mif\u001b[39;00m device\u001b[39m.\u001b[39;49mstartswith(\u001b[39m\"\u001b[39m\u001b[39mmps\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m     54\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlstm(x, lstm_init)[\u001b[39m0\u001b[39m][\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, :, :]\n\u001b[1;32m     55\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'torch.device' object has no attribute 'startswith'"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "# Start training\n",
    "predicted_labels = [] \n",
    "correct_labels = []\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    # Initialize loss/accuracy variables\n",
    "    losses = {\"train\": 0, \"val\": 0, \"test\": 0}\n",
    "    accuracies = {\"train\": 0, \"val\": 0, \"test\": 0}\n",
    "    counts = {\"train\": 0, \"val\": 0, \"test\": 0}\n",
    "    \n",
    "    # Adjust learning rate for SGD\n",
    "    if OPTIMIZER == \"SGD\":\n",
    "        lr = LEARNING_RATE * (LEARNING_RATE_DECAY_BY ** (epoch // LEARNING_RATE_DECAY_EVERY))\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group[\"lr\"] = lr\n",
    "    \n",
    "    # Process each split\n",
    "    for split in (\"train\", \"val\", \"test\"):\n",
    "        # Set network mode\n",
    "        if split == \"train\":\n",
    "            model.train()\n",
    "            torch.set_grad_enabled(True)\n",
    "        else:\n",
    "            model.eval()\n",
    "            torch.set_grad_enabled(False)\n",
    "        \n",
    "        # Process all split batches\n",
    "        for i, (input, target) in enumerate(loaders[split]):\n",
    "            \n",
    "            # Move tensors to device\n",
    "            input = input.to(DEVICE)\n",
    "            target = target.to(DEVICE)\n",
    "            \n",
    "            if DEBUG:\n",
    "                print(input.device)\n",
    "\n",
    "            # Forward\n",
    "            output = model(input)\n",
    "\n",
    "            # Compute loss\n",
    "            loss = F.cross_entropy(output, target)\n",
    "            losses[split] += loss.item()\n",
    "            \n",
    "            # Compute accuracy\n",
    "            _, pred = output.data.max(1)\n",
    "            correct = pred.eq(target.data).sum().item()\n",
    "            accuracy = correct / input.data.size(0)   \n",
    "            accuracies[split] += accuracy\n",
    "            counts[split] += 1\n",
    "            \n",
    "            # Backward and optimize\n",
    "            if split == \"train\":\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "    \n",
    "    # Print info at the end of the epoch\n",
    "    if accuracies[\"val\"] / counts[\"val\"] >= best_accuracy_val:\n",
    "        best_accuracy_val = accuracies[\"val\"] / counts[\"val\"]\n",
    "        best_accuracy = accuracies[\"test\"] / counts[\"test\"]\n",
    "        best_epoch = epoch\n",
    "\n",
    "    train_loss = losses[\"train\"] / counts[\"train\"]\n",
    "    train_accuracy = accuracies[\"train\"] / counts[\"train\"]\n",
    "    validation_loss = losses[\"val\"] / counts[\"val\"]\n",
    "    validation_accuracy = accuracies[\"val\"] / counts[\"val\"]\n",
    "    test_loss = losses[\"test\"] / counts[\"test\"]\n",
    "    test_accuracy = accuracies[\"test\"] / counts[\"test\"]\n",
    "\n",
    "    print(\"\\nINFO\")\n",
    "    print(f\"- Model: {MODEL_TYPE}\")\n",
    "    print(f\"- Subject: {SUBJECT}\")\n",
    "    print(f\"- Time interval: [{TIME_LOW}-{TIME_HIGH}] [{TIME_LOW}-{TIME_HIGH} Hz]\")\n",
    "    print(f\"- Epoch: {epoch}\")\n",
    "    print(\"\\nSTATS\")\n",
    "    print(f\"- Training: Loss {train_loss:.4f}, Accuracy {train_accuracy:.4f}\")\n",
    "    print(f\"- Validation: Loss {validation_loss:.4f}, Accuracy {validation_accuracy:.4f}\")\n",
    "    print(f\"- Test: Loss {test_loss:.4f}, Accuracy {test_accuracy:.4f}\")\n",
    "    print(f\"Best Test Accuracy at maximum Validation Accuracy (validation_accuracy = {best_accuracy_val:.4f}) is {best_accuracy:.4f} at epoch {best_epoch}\")\n",
    "\n",
    "    losses_per_epoch[\"train\"].append(train_loss)\n",
    "    losses_per_epoch[\"val\"].append(validation_loss)\n",
    "    losses_per_epoch[\"test\"].append(test_loss)\n",
    "    accuracies_per_epoch[\"train\"].append(train_accuracy)\n",
    "    accuracies_per_epoch[\"val\"].append(validation_accuracy)\n",
    "    accuracies_per_epoch[\"test\"].append(test_accuracy)\n",
    "\n",
    "    if epoch % SAVE_CHECK == 0:\n",
    "        torch.save(model, CHECKPOINT_PATH / f\"{MODEL_TYPE}__subject{SUBJECT}_epoch_{epoch}.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('nightly-pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "52066f274ad47fc5df40955e976bae6c795dfc7e7f542305f49a0cfb9aa36af3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
